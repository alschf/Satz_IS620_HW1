{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Random forest gave the best result with a 5% error rate (on a test set of ~1600 samples).\n",
    "BernoulliNB give an 11% error when binarizing at 0.0, while a decision tree gives ~10% error rate.\n",
    "\n",
    "The data was randomized and split into a 4000 training set and 1600 test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import random\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#import copy\n",
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPercErrorRate(ans, y_test):\n",
    "    er = 0\n",
    "    for x in range(0, len(ans)):\n",
    "        if ans[x] != y_test[x]:\n",
    "            er += 1\n",
    "    return 100*er/float(len(ans))\n",
    "\n",
    "def binerize(threshold, lis):\n",
    "    lnew = []\n",
    "    for x in lis:\n",
    "        temp = []\n",
    "        for y in x:\n",
    "            \n",
    "            if float(y)>threshold:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        lnew.append(temp)\n",
    "    return lnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/Users/alexandersatz/Documents/Cuny/IS620/classifySpam/spambase.data', 'r') as f:\n",
    "    l1 = []\n",
    "    for line in f:\n",
    "        line = line.strip('\\n\\r')\n",
    "        line = line.split(\",\")\n",
    "        l1.append(line)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We break down our data set into a training set of 3000 and a test set of 1601.\n",
    "The inputs are also non-standardized, standardized, and/or normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lx1, ly = [],[]\n",
    "for x in l1:\n",
    "    lx1.append(x[:-1])\n",
    "    ly.append(int(x[-1]))\n",
    "lx = []\n",
    "for x in lx1:\n",
    "    t = []\n",
    "    for y in x:\n",
    "        t.append(float(y))\n",
    "    lx.append(t)\n",
    "    \n",
    "lx_normalized = []\n",
    "for x in lx1:\n",
    "    t = []\n",
    "    for y in x:\n",
    "        t.append(float(y))\n",
    "    t = np.asarray(t)\n",
    "    t = scale( t, axis=0, with_mean=True, with_std=True, copy=True )\n",
    "    lx_normalized.append(t)\n",
    "    \n",
    "lx_scaled = []\n",
    "for x in lx1:\n",
    "    t = []\n",
    "    for y in x:\n",
    "        t.append(float(y))\n",
    "    t = np.asarray(t)\n",
    "    t = t/t.max()\n",
    "    lx_scaled.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest = lx[:3000], lx[3000:]\n",
    "ytrain, ytest = ly[:3000], ly[3000:]\n",
    "xtrain_n, xtest_n = lx_normalized[:3000], lx_normalized[3000:]\n",
    "xtrain_s, xtest_s = lx_scaled[:3000], lx_scaled[3000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we look at sklearn decision trees with two different classifiers.  \n",
    "We see error rates of 10% either way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.118675827607746"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPercErrorRate(ans, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.680824484697064"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()  ## uses gini by default\n",
    "clf.fit(xtrain, ytrain)\n",
    "ans = clf.predict(xtest)\n",
    "getPercErrorRate(ans, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the bernoulli naive bayes.  Best result is with binarizing at 0.0 with unscaled, or scaled data.  Normalized data does not give a good result.  This gives an 11% error at best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.118051217988757"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xbinary = binerize(1.0, xtrain)\n",
    "clf = BernoulliNB()\n",
    "clf.fit(xtrain, ytrain)\n",
    "ans = clf.predict(xtest)\n",
    "getPercErrorRate(ans, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.6058713304 0\n",
      "36.5396627108 1\n",
      "35.6027482823 2\n",
      "36.7895065584 3\n",
      "37.9762648345 4\n",
      "37.7888819488 5\n",
      "37.4765771393 6\n",
      "37.1642723298 7\n",
      "38.1636477202 8\n",
      "37.8513429107 9\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,10):\n",
    "    clf = BernoulliNB(binarize = x/10.0)\n",
    "    clf.fit(xtrain_n, ytrain)\n",
    "    ans = clf.predict(xtest_n)\n",
    "    print str(getPercErrorRate(ans, ytest)) + \" \" + str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.118051218 0\n",
      "30.7932542161 1\n",
      "35.6027482823 2\n",
      "37.7264209869 3\n",
      "37.1018113679 4\n",
      "37.4765771393 5\n",
      "37.039350406 6\n",
      "37.9762648345 7\n",
      "37.2267332917 8\n",
      "36.2273579013 9\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,10):\n",
    "    clf = BernoulliNB(binarize = x/40.0)\n",
    "    clf.fit(xtrain_s, ytrain)\n",
    "    ans = clf.predict(xtest_s)\n",
    "    print str(getPercErrorRate(ans, ytest)) + \" \" + str(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian naive bayes does very badly with normalized or standardized data at >23% error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.16489693941287"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(xtrain_n, ytrain)\n",
    "ans = clf.predict(xtest_n)\n",
    "getPercErrorRate(ans, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.672704559650217"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(xtrain_s, ytrain)\n",
    "ans = clf.predict(xtest_s)\n",
    "getPercErrorRate(ans, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest gives an error as low as 5% with n_estimators set at 20.  Changing the max features setting didn't improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.9906308557 2\n",
      "11.9300437227 4\n",
      "10.493441599 6\n",
      "8.68207370394 8\n",
      "8.11992504685 10\n",
      "9.30668332292 12\n",
      "8.49469081824 14\n",
      "8.86945658963 16\n",
      "7.30793254216 18\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,10):\n",
    "    clf = RandomForestClassifier(n_estimators=x*2)\n",
    "    clf.fit(xtrain_n, ytrain)\n",
    "    ans = clf.predict(xtest_n)\n",
    "    print str(getPercErrorRate(ans, ytest)) + \" \" + str(x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.18238600874 3\n",
      "7.18301061836 6\n",
      "6.18363522798 9\n",
      "5.2467207995 12\n",
      "5.1217988757 15\n",
      "4.80949406621 18\n",
      "4.37226733292 21\n",
      "5.3091817614 24\n",
      "4.74703310431 27\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,10):\n",
    "    clf = RandomForestClassifier(n_estimators=x*3)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    ans = clf.predict(xtest)\n",
    "    print str(getPercErrorRate(ans, ytest)) + \" \" + str(x*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MultinomialNB does poorly (>23% errors).  When the data is binarized prior to fitting, the error drops to 9%, which is basically the same as the BernoulliNB as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.663335415365395"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()  \n",
    "clf.fit(xtrain_s, ytrain)\n",
    "ans = clf.predict(xtest_s)\n",
    "getPercErrorRate(ans, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.735165521549032"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain, ytrain)\n",
    "ans = clf.predict(xtest)\n",
    "getPercErrorRate(ans, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.119300437226734"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbinary = binerize(0.0, xtrain_s)\n",
    "xtest_bin = binerize(0.0, xtest_s) \n",
    "clf = MultinomialNB()\n",
    "clf.fit(xbinary, ytrain)\n",
    "ans = clf.predict(xtest_bin)\n",
    "getPercErrorRate(ans, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
